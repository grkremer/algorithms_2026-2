{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29b4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# -------------------------\n",
    "# Implementação da Árvore\n",
    "# -------------------------\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, n_features=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_features = n_features\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(set(y))\n",
    "        self.n_features = X.shape[1] if not self.n_features else self.n_features\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_labels = len(np.unique(y))\n",
    "\n",
    "        if (depth >= self.max_depth or num_labels == 1 or num_samples < self.min_samples_split):\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        feat_idxs = np.random.choice(num_features, self.n_features, replace=False)\n",
    "\n",
    "        # Melhor split\n",
    "        best_feat, best_thresh = self._best_split(X, y, feat_idxs)\n",
    "        if best_feat is None:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        # Splitar dados\n",
    "        indices_left = X[:, best_feat] <= best_thresh\n",
    "        X_left, y_left = X[indices_left], y[indices_left]\n",
    "        X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "\n",
    "        left_child = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        right_child = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return (best_feat, best_thresh, left_child, right_child)\n",
    "\n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        best_gini = 1.0\n",
    "        best_idx, best_thresh = None, None\n",
    "\n",
    "        for idx in feat_idxs:\n",
    "            thresholds = np.unique(X[:, idx])\n",
    "            for thr in thresholds:\n",
    "                gini = self._gini_index(y, X[:, idx], thr)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thresh = thr\n",
    "        return best_idx, best_thresh\n",
    "\n",
    "    def _gini_index(self, y, feature_values, threshold):\n",
    "        left_mask = feature_values <= threshold\n",
    "        right_mask = ~left_mask\n",
    "        if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "            return 1.0\n",
    "\n",
    "        def gini_group(labels):\n",
    "            m = len(labels)\n",
    "            counts = np.bincount(labels)\n",
    "            return 1.0 - sum((count / m) ** 2 for count in counts if count > 0)\n",
    "\n",
    "        left_gini = gini_group(y[left_mask])\n",
    "        right_gini = gini_group(y[right_mask])\n",
    "        m = len(y)\n",
    "        return (np.sum(left_mask) / m) * left_gini + (np.sum(right_mask) / m) * right_gini\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs, self.tree) for inputs in X])\n",
    "\n",
    "    def _predict(self, inputs, tree):\n",
    "        if not isinstance(tree, tuple):\n",
    "            return tree\n",
    "        feat_idx, threshold, left_child, right_child = tree\n",
    "        if inputs[feat_idx] <= threshold:\n",
    "            return self._predict(inputs, left_child)\n",
    "        else:\n",
    "            return self._predict(inputs, right_child)\n",
    "\n",
    "# -------------------------\n",
    "# Implementação do Random Forest\n",
    "# -------------------------\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=None, min_samples_split=2, n_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_features = n_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTree(max_depth=self.max_depth,\n",
    "                                min_samples_split=self.min_samples_split,\n",
    "                                n_features=self.n_features)\n",
    "            # Bootstrap sample\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        # Votação majoritária\n",
    "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
    "        return np.array([Counter(preds).most_common(1)[0][0] for preds in tree_preds])\n",
    "\n",
    "# -------------------------\n",
    "# Exemplo de uso\n",
    "# -------------------------\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data = load_iris()\n",
    "    X, y = data.data, data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = RandomForest(n_trees=10, max_depth=5, n_features=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = np.mean(y_pred == y_test)\n",
    "    print(f\"Acurácia: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
